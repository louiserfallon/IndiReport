---
title: "Business Use Cases of Panel Scanner Data in the Retail Industry"
author: 'Louise Fallon - CID: 01262763'
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2) #for ggplot and plotting functions
library(mlogit) #for mlogit functions
library(data.table) # for data.table functions, aggregation etc.
library(gsubfn) #for gsubfn multiple-string-replace function 
library(knitr) #for kable markdown tables
source("mlogittotable.R")
```

\newpage

##Abstract

The introduction of panel scanner data led to new analytical methods in the retail industry. This report describes, if an analyst has access to panel scanner data for a manufacturer or retailer, what analysis can be done, how simple is this to do, and what business value it could provide. This is supported by an example using a sample of panel scanner data for carbonated beverages to illustrate possible outputs, insights, and corresponding business actions. Choice models are explored in detail, including techniques for calculating brand share elasticity and promotional effectiveness. Extensions to the model and alternative modelling approaches are explored, and inclusion of social media data is discussed. 

##Introduction

Panel scanner data is a category of retail data created by participating households repeatedly scanning products bought across a variety of stores over a period of time. Wideley refered to as UPC panel data, from the Universal Product Code that is scanned in the process, this kind of data became widely available to the field of marketing science throughout the 1980s (Guadagni & Little, 2008), and has been used for a variety of business use cases (Bucklin & Gupta 1999). The introduction of UPC Data meant that households' purchasing decisions over time could be explored, rather than only aggregate store level sales data which had been predominant.

![Prevalence of "UPC scanner" in Google ngram corpus since 1970 (Google ngrams, 2008)](upcscannerngram.png)

This data is often used to build models of consumer choice. These models are not usually made to be predictive, but rather interpretative, to understand consumer behaviour, and reactions to different marketing changes such as price changes, promotion changes and product availability. The outcome of the models often include a set of price and cross price elasticities, which can be used to visualise competitive structure. Consumer choice models can also be used to simulate consumer reactions to price, promotion, display and product changes, so business practitioners can test these changes before making the often costly decisions to bring the changes to market. 

This report uses an example of a carbonated soft drink data set to explain the steps that need to be taken in order to build a model of consumer choice. At each step there is a discussion of the decisions that an analyst, undertaking this kind of analysis for a retailer or manufacturer, would need to make to ensure that the analysis provides business value. 

##Data Description and Preprocessing

```{r loaddata}
fulldata <- read.csv("../Data/CarbonatesBottlesandCans (confidential).csv", fileEncoding = "latin1")
```

```{r exploratoryanalysis, eval=FALSE}
#households
tmp <- as.data.frame(table(fulldata$HOUSE))
plot(tmp$Freq)
boxplot(tmp$Freq)
mean(tmp$Freq)
median(tmp$Freq) 
nrow(tmp) #29214 households
nrow(tmp[tmp$Freq>=5,])/nrow(tmp) #81% of households have more than 5 observations
nrow(tmp[tmp$Freq>=50,])/nrow(tmp) #25% of households have more than 50 observations

#stores
tmp <- as.data.frame(table(fulldata$shop_desc))
tmp$Var1 <- factor(tmp$Var1, levels = tmp$Var1[order(tmp$Freq, decreasing = TRUE)])
ggplot(tmp, aes(x=Var1, y=Freq)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
nrow(tmp[tmp$Freq>=500,])/nrow(tmp) #95% of stores have more than 500 observations

#categories
tmp <- as.data.frame(table(fulldata$cat_name))
tmp$Var1 <- factor(tmp$Var1, levels = tmp$Var1[order(tmp$Freq, decreasing = TRUE)])
ggplot(tmp, aes(x=Var1, y=Freq)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("all categories")

#subcategories
tmp <- as.data.frame(table(fulldata$sub_cat_name))
tmp$Var1 <- factor(tmp$Var1, levels = tmp$Var1[order(tmp$Freq, decreasing = TRUE)])
ggplot(tmp, aes(x=Var1, y=Freq)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("top subcategories")

#brands
tmp <- as.data.frame(table(fulldata$brand_name))
nrow(tmp) #170 brands
tmp <- tmp[tmp$Freq > 1.5*mean(tmp$Freq),]
tmp$Var1 <- factor(tmp$Var1, levels = tmp$Var1[order(tmp$Freq, decreasing = TRUE)])
ggplot(tmp, aes(x=Var1, y=Freq)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1))

#range
tmp <- as.data.frame(table(fulldata$total_range_name))
nrow(tmp) #215 ranges
tmp <- tmp[tmp$Freq > 1.5*mean(tmp$Freq),]
tmp$Var1 <- factor(tmp$Var1, levels = tmp$Var1[order(tmp$Freq, decreasing = TRUE)])
ggplot(tmp, aes(x=Var1, y=Freq)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1))

#epromdesc
tmp <- as.data.frame(table(fulldata$epromdesc))
nrow(tmp) #362 promotions
tmp <- tmp[tmp$Freq > 1.5*mean(tmp$Freq),]
tmp$Var1 <- factor(tmp$Var1, levels = tmp$Var1[order(tmp$Freq, decreasing = TRUE)])
ggplot(tmp, aes(x=Var1, y=Freq)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
nrow(fulldata[!fulldata$epromdesc == "No Promotion",])/nrow(fulldata) #59% of observations have some promotion 

#looks like brand aggregates to store standard and value, whereas range has the actual stores (e.g. asda)
fulldata$date <- paste(fulldata$relweek,fulldata$DAY, sep="-")
length(unique(fulldata$date)) #364 days

##brand hierarchy (ensure bottom 3 include top 1)
fulldata$temp = paste(fulldata$total_range_name, fulldata$cat_name, fulldata$sub_cat_name)
brand <- aggregate(brand_name ~ temp, data=fulldata, FUN=function(x) length(unique(x)))
head(brand)

fulldata$volperpack = fulldata$Volume/fulldata$PACKS

```

```{r}
fulldata$date <- paste(fulldata$relweek,fulldata$DAY, sep="-")
fulldata$volperpack = fulldata$Volume/fulldata$PACKS

#take data only from the top retailer
data_ind_summary_pre <- fulldata[fulldata$shop_desc %in% c("1TESCO") &
                                fulldata$cat_name %in% c("Canned Colas","Canned Lemonade","Canned Other Flavours"),]


#prepare data to be aggregated
#by date, shop, household, range name, cat name and sub cat name
data_ind_summary_pre$product <- paste(data_ind_summary_pre$total_range_name, data_ind_summary_pre$sub_cat_name)
data_ind_summary_pre$key <- paste(data_ind_summary_pre$date, data_ind_summary_pre$shop_desc, data_ind_summary_pre$HOUSE, data_ind_summary_pre$product)
data_ind_summary_dt <- data.table(data_ind_summary_pre)
setkey(data_ind_summary_dt, key)

#aggregate and get:
#price per unit: count rows and sum net spend
#brand name tail, sub cat name tail, binary tail

df_ind_summary <- as.data.frame(data_ind_summary_dt[,
                        j=list(tail(date,1),
                               tail(HOUSE,1),
                               tail(shop_desc,1),
                               tail(product,1),
                               tail(sub_cat_name,1),
                               tail(cat_name,1),
                               tail(brand_name,1),
                               tail(epromdesc,1),
                               sum(Volume),
                               sum(NETSPEND,1)),
                        by=key])

colnames(df_ind_summary) <- c("key","date","HOUSE","shop_desc","product",
                             "sub_cat_name","cat_name", "brand_name", "epromdesc",
                             "Volume", "NETSPEND")
df_ind_summary$priceper330ml <- df_ind_summary$NETSPEND /  df_ind_summary$Volume *.33
```

```{r}
df_ind_summary$product[df_ind_summary$brand_name == "PL_Standard" & 
                         df_ind_summary$sub_cat_name == "Diet"] <- "Own Brand Diet"
df_ind_summary$product[df_ind_summary$brand_name == "PL_Standard" &
                         df_ind_summary$sub_cat_name == "Regular"] <- "Own Brand Regular"

tmp <- as.data.frame(table(df_ind_summary$product))
tmp$Var1 <- factor(tmp$Var1, levels = tmp$Var1[order(tmp$Freq, decreasing = TRUE)])
tmp <- tmp[order(tmp$Freq, decreasing = TRUE),]

#take top 22 products
tmpprods <- head(tmp$Var1,19)

df_ind_summary$product[!df_ind_summary$product %in% tmpprods] <- "Other"
```

The data used as an example of these techniques is made up of around 29,000 UK households' purchases of canned and bottled carbonated soft drinks over a year, from December 2014 to December 2015 (hereafter referred to as the CSD data). The available variables are summarised in Table 1.

```{r}
kable(data.frame(variable=c("Date","Household", "Shop","Product", "Promotion","Volume","Price"),
                 description=c("Relative year, week and day of the shopping trip",
                               "Identifier of the household making the shopping trip",
                               "Name of the retailer",
                               "Category, Sub Category, Range and Brand Name",
                               "Description of promotion for that product at the time",
                               "Size (in litres) of the product",
                               "Amount spent on the product")), caption="CSD Data Variable Description")
```

The analysis uses only data from the top retailer, as more reliable data is available on product availability for this store, and to reduce computational run-time. Varying sizes of beverages are included, for example, 330ml cans and 2 litre bottles. The analysis is made meaningful by focusing only on the category of canned drinks, to focus on true competitors. Own brand products are treated as one product, and low volume brands are grouped together to narrow the data to 20 products. The price range for these products can be seen in Figure 2. Energy drinks such as Red Bull have a higher price than average, and interestingly, it does not seem like own brand products have a lower price than average, which may be because "the use of price promotions for fast moving consumer goods (FMCG’s) by supermarkets has increased substantially over the last decade" (Malik, 2015), particularly for branded products.

```{r}
producttable <- as.data.frame(table(df_ind_summary$product))
producttable <- producttable[order(producttable$Freq, decreasing = TRUE),]
df_ind_summary$product <- factor(df_ind_summary$product, levels = rev(producttable$Var1))

ggplot(df_ind_summary, aes(x= product, y=priceper330ml)) + 
  geom_boxplot(color="darkblue") + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  xlab("Product") + ylab("Price (£) per 330ml")  + coord_flip()
```

Figure 2: CSD Data Product Price Ranges

Choice models require the set of available alternatives and prices at the time the shopper made the decision, therefore the CSD data had to be processed to identify which products were available in each store over the time period, based on what other households bought. Ideally this data would be provided in the dataset, as the imputation is not necessarily fully comprehensive, as alternatives may not have been purchased that day. 

The dataset used is missing “feature” and “display” variables that are commonly included, and used in this type of analysis (Zhang 2006), these are important variables that influence consumer choice. Omitted variable bias may occur if these are not included, as brand placement in a prominent place on the store shelf may influence both consumer choice and price sensitivity. The analyst should ensure that these variables are available or that the business is aware of the potential bias in the results.

The model will be of consumer choice within a category, assuming that the consumer has already decided to make a purchase within that category. For this reason the definition of "category" and which products are included within each category is incredibly important, for example: "Should different flavors, or colors, or sizes be treated as different products or lumped together?" (Guadagni & Little 1983).

The preparation of data before running a choice model is therefore highly important. Andrews & Currim (2005) recommend that analysis is done at the lowest level (the SKU) if possible, modelling at the SKU level was popularised by Fader & Hardie (1996). This may well improve predictive performance, but if the business wants analysis at the brand level, then it may be more dangerous to do this aggregation post-modelling, as it is not always theoretically sound to aggregate effects, especially if the model is non-linear, as the multinomial logit model is. The CSD data was analysed at the lowest level of the data provided, except for the "Other", and "Private Label" categories.

Andrews & Currim (2005) also find that, when aggregating, averaging prices causes the price coefficient to be inflated, whereas taking the maximum of a binary promotion variable causes the promotion coefficient to be underestimated. These two findings imply that it makes sense only to aggregate products for which the coefficients are not of primary importance, in this case private label brands and “other” less important brands.

Depending on what technology and infrastructure is being used to run the model, multinomial logit modelling can be quite computationally expensive. Andrews & Currim (2005) offer advice on this as well, with a result that "selecting purchases of n households over w weeks is slightly preferred over selecting purchases of 2n households over w / 2 weeks", so if the data is to be subset then a subset over households instead of time is preferable.

#Modelling Methodology

The processed dataset then constitutes a set of revealed preferences - the purchases that consumers actually made, as opposed to stated preferences - the products that the consumers explicitly say they like the best. This structure of data allows a mixed multinomial logit model to be run, which became the default after the seminal work of Guadagni & Little (1983). This is an econometric tool that estimates the utility of each product (j) for each consumer (i) $V_{i,j}$ as a linear combination of explanatory variables, either belonging to the household (e.g.  income), or the properties of the product (e.g. price):

$V_{i,j} = \beta_1 + \beta_2 x_{i} +  \beta_3 x_{i,j} + \dots$

by modeling the  probability of making a particular choice as per the logit equation, where the probability of consumer i choosing product j is a function of the relative utility:

$Prob_{i,j} = \frac{e^{V_{i,j}}}{\Sigma_{(k \in K)} e^{V_{i,k}}}$

The key product level explanatory variables are price and promotion, which are supplemented by household level variables calculated from the data. The dataset did not already contain household-specific variables such as income or number of children, to be used as additional explanatory variables in the model, despite the fact they are often included as part of a UPC dataset. However, as there was a large enough time window, it was possible to calculate household-level variables from an initialisation period of the initialisation period (the first 60 days).

In this case a loyalty variable was calculated: the proportion spent on each brand in the initialisation period. An average spend variable was also calculated for each household: the average vaule spent in the category per week over the first month. Finally, the total purchase incidence was calculated: the number of times the household made purchases in the first month. The data was then limited to households that made some purchases in the initialisation period, to avoid erroneous missing data for these initialisation variables. These variables account for some of the heterogeneity across households.

The final model was then estimated using a multinomial logistic regression model using the mlogit package (Croissant, Y. 2012), and was of the form:

$V_{i,j} = \alpha_j + \beta_1 price_{i,j}  + \beta_2 loyalty_{i,j} + \beta_3 promotion_{i,j}  + \beta_{4_j} purchase frequency_{i} + \beta_{5_j} averagespend_{i} + \epsilon$

The intercept is alternative-specific, and represents the "base" utility of the product, relative to the reference product. Price, loyalty and promotion are alternative-specific but have universal coefficients, meaning that there are different prices across products and time, but that consumers have a universal reaction to a change in price, regardless of the product. Purchase frequency and average spend are individal-specific and have alternative-specific coefficients, meaning that there is one, unchanging value per household, but that consumers may have a different relationship with that variable for each product. For example, consumers with a higher average spend may be more likely to purchase premium brands, so have positive $beta_{4_j}$ coefficients for premium brands and negative $beta_{4_j}$ coefficients for everyday brands.

The choice of variables in the model, and which way they should be modelled, is highly important for an analyst to decide, and to understand the implications for interpretation of coefficients.

```{r}
initialisationperiod <- unique(df_ind_summary$date)[1:60]
df_ind_summary_init <- df_ind_summary[df_ind_summary$date %in% initialisationperiod,]

#get list of households in initialisation period
init_households <- unique(df_ind_summary_init$HOUSE)

#get total purchase incidences
totalpurchases <- data.frame(table(df_ind_summary_init$HOUSE))
colnames(totalpurchases) <- c("HOUSE","purchasefreq")

#get average purchase total
avgspend <- aggregate(NETSPEND ~ HOUSE, data = df_ind_summary_init, mean)
colnames(avgspend) <- c("HOUSE","avgspend")

#get proportion of spend per product
df_ind_summary_init_reshape <- dcast(data = df_ind_summary_init,
                                    formula = HOUSE~product,
                                    fun.aggregate = length,value.var = "NETSPEND")

df_rsums = rowSums(df_ind_summary_init_reshape[,2:length(df_ind_summary_init_reshape)])
df_ind_summary_init_reshape[df_rsums < 5,2:length(df_ind_summary_init_reshape)] <- 0

brandproportions <- cbind(id = df_ind_summary_init_reshape[, 1], df_ind_summary_init_reshape[, -1]/rowSums(df_ind_summary_init_reshape[, -1]))
brandproportions[is.na(brandproportions)] <- 0

colnames(brandproportions) <- paste("loyalty.",gsubfn(".",list(" " = "", "." = "", "(" = "", ")" = ""), colnames(brandproportions)), sep="")
colnames(brandproportions)[1] <- "HOUSE"
```

```{r pricewidecalc, eval=FALSE}
df_ind_summary <- df_ind_summary[!df_ind_summary$date %in% initialisationperiod,]
#Impute prices and availability from data
df_ind_summary$index = 1: nrow(df_ind_summary)
  
#Gets the prices for all products in that shop on that date
findfunction <- function(x, date, shop) {
  if (sum(df_ind_summary$product == x["Var1"] &
                     df_ind_summary$date == date &
                     df_ind_summary$shop == shop) > 0) {return(mean(df_ind_summary$priceper330ml[
                     df_ind_summary$product == x["Var1"] &
                     df_ind_summary$date == date &
                     df_ind_summary$shop == shop]))
                     } else {return(0)}
}

f <- function(x, output) {
    print(as.numeric(x["index"])/nrow(df_ind_summary))
    return(apply(producttable,1, findfunction, x["date"], x["shop_desc"]))
 }

df_ind_summary_wide <- apply(df_ind_summary, 1, f)
rownames(df_ind_summary_wide) <- producttable$Var1
write.csv(df_ind_summary_wide,"df_ind_summary_wide.csv")
```

```{r promowidecalc, eval=FALSE}
df_ind_summary <- df_ind_summary[!df_ind_summary$date %in% initialisationperiod, ]
df_ind_summary$promotion <- 1
df_ind_summary$promotion[df_ind_summary$eprom %in% c("No Promotion"," No Promotion (Price Marked)")] <- 0

#Impute prices and availability from data
df_ind_summary$index = 1:nrow(df_ind_summary)
  
#Gets the prices for all products in that shop on that date
findfunction <- function(x, date, shop) {
  if (sum(df_ind_summary$product == x["Var1"] &
                     df_ind_summary$date == date &
                     df_ind_summary$shop == shop) > 0) {return(max(df_ind_summary$promotion[
                     df_ind_summary$product == x["Var1"] &
                     df_ind_summary$date == date &
                     df_ind_summary$shop == shop]))
                     } else {return(0)}
}

f <- function(x, output) {
    print(as.numeric(x["index"])/119742)
    return(apply(producttable,1, findfunction, x["date"], x["shop_desc"]))
 }

df_ind_summary_wide_prom <- apply(df_ind_summary, 1, f)
rownames(df_ind_summary_wide_prom) <- producttable$Var1
write.csv(df_ind_summary_wide_prom,"df_ind_summary_wide_prom.csv")
```

```{r loadwidedata, eval=FALSE}
df_ind_summary_wide_prom <- read.csv("df_ind_summary_wide_prom.csv")
df_ind_summary_wide_prom_matrix <- data.matrix(df_ind_summary_wide_prom[2:dim(df_ind_summary_wide_prom)[2]])

df_ind_summary_wide <- read.csv("df_ind_summary_wide.csv")
df_ind_summary_wide_matrix <- data.matrix(df_ind_summary_wide[2:dim(df_ind_summary_wide)[2]])
```

```{r processwidedata, eval=FALSE}
#Make promotion dataframe by transposing and adding "prom." to column names
df_ind_summary_wide_prom_t <- data.frame(t(df_ind_summary_wide_prom_matrix))

colnames(df_ind_summary_wide_prom_t) <- paste("prom.", gsubfn(".",
                                             list(" " = "", "." = "", "(" = "", ")" = ""),
                                             as.character(df_ind_summary_wide_prom$X)),
                                             sep="")

#Make price dataframe by transposing and adding "price." to column names
df_ind_summary_wide_t <- data.frame(t(df_ind_summary_wide_matrix))
names(df_ind_summary_wide_t) <- paste("price.", gsubfn(".",
                                             list(" " = "", "." = "", "(" = "", ")" = ""),
                                             as.character(df_ind_summary_wide[,1])), sep="")
#Make availability dataframe by checking if price = 0 and adding ".availability" to col names
availability <- data.frame(apply(df_ind_summary_wide_matrix, 1, function(x) {x != 0}))
names(availability) <- paste("availability.",gsubfn(".",
                                    list(" " = "", "." = "", "(" = "", ")" = ""),
                                    as.character(df_ind_summary_wide[,1])), sep="")
##concatenate required fields for mlogit
df_ind_summary_extended <- cbind(df_ind_summary[,c("date","shop_desc","product","HOUSE")],
                                 df_ind_summary_wide_t,availability, df_ind_summary_wide_prom_t)

##136 df_ind_summary_wide_t
##134 df_ind_summary_wide_prom_t

df_ind_summary_extended$product <- gsubfn(".",
                                          list(" " = "", "." = "", "(" = "", ")" = ""),
                                          as.character(df_ind_summary_extended$product))
df_ind_summary_extended <- df_ind_summary_extended[!df_ind_summary_extended$date %in% initialisationperiod,]
df_ind_summary_extended <- df_ind_summary_extended[df_ind_summary_extended$HOUSE %in% init_households,]
df_ind_summary_extended <- merge(df_ind_summary_extended, totalpurchases)
df_ind_summary_extended <- merge(df_ind_summary_extended, avgspend)
df_ind_summary_extended <- merge(df_ind_summary_extended, brandproportions)

save(df_ind_summary_extended, file="df_ind_summary_extended.RData")
```

```{r loadextendeddata}
load("df_ind_summary_extended.RData")
```

```{r converttomlogitdata, eval=FALSE}
#takes 1 min to run
#create data frame with all data, including availability (in wide format)
temp_mlogit <- mlogit.data(df_ind_summary_extended,
                           shape = "wide",
                           varying = c(price=5:24,
                                       availability=25:44,
                                       prom=45:64,
                                       loyalty=67:86),
                           choice = "product", id.var = "HOUSE")
#subset only to the products that are available
temp_available <-  temp_mlogit[temp_mlogit$availability ,] 
temp_available <- temp_available[ , !(names(temp_available) %in% "availability")]

#and resend it through mlogit.data with format long 
csds.data <- mlogit.data(temp_available , choice = 'product', shape = "long" , alt.var = "alt" ,  chid.var = "chid")

save(csds.data, file="csdsdata14.RData")
```

```{r toremove, eval=FALSE}
#takes 1 min to run
#create data frame with all data, including availability (in wide format)
temp_mlogit <- mlogit.data(df_ind_summary_extended[df_ind_summary_extended$HOUSE %in% 
                                                     c( #7up
                                                       720868,170463,
                                                       #DC
                                                       741317,31969),
                                                   c("HOUSE","date","product",
                                                     "price.DietCokeDiet", "price.Other",
                                                     "price.TangoRegular", "price.DrPepperRegular",
                                                     "price.7UpRegular", "price.RelentlessRegular",
                                                     "price.FantaDiet", "price.FantaRegular",
                                                     "price.RedBullRegular",
                                                     "availability.DietCokeDiet", "availability.Other",
                                                     "availability.TangoRegular", "availability.DrPepperRegular",
                                                     "availability.7UpRegular", "availability.RelentlessRegular",
                                                     "availability.FantaDiet", "availability.FantaRegular",
                                                     "availability.RedBullRegular",
                                                     "loyalty.DietCokeDiet", "loyalty.Other",
                                                     "loyalty.TangoRegular", "loyalty.DrPepperRegular",
                                                     "loyalty.7UpRegular", "loyalty.RelentlessRegular",
                                                     "loyalty.FantaDiet", "loyalty.FantaRegular",
                                                     "loyalty.RedBullRegular",
                                                     "purchasefreq","avgspend")],
                           shape = "wide",
                           varying = c(price=4:12,
                                       availability=13:21,
                                       loyalty=22:30),
                           choice = "product", id.var = "HOUSE")
#subset only to the products that are available
temp_available <-  temp_mlogit[temp_mlogit$availability ,] 
temp_available <- temp_available[ , !(names(temp_available) %in% "availability")]

#and resend it through mlogit.data with format long 
csds.data <- mlogit.data(temp_available , choice = 'product', shape = "long" , alt.var = "alt" ,  chid.var = "chid")

save(csds.data, file="csdsdata9.RData")
```

```{r runmodel, eval=FALSE}
#takes 1h30 to run
Sys.time()
csds.ml14 <- mlogit(product ~ price + loyalty + prom | avgspend + purchasefreq, csds.data)
Sys.time()
summary(csds.ml14)

save(csds.ml14, file="csdsml14.RData")

#takes 1h30 to run
Sys.time()
csds.ml15 <- mlogit(product ~ price + loyalty + prom, csds.data)
Sys.time()
summary(csds.ml15)

save(csds.ml15, file="csdsml15.RData")
```

#Results and Visualisation

```{r shareofchoice}
load("csdsml14.RData")
csds.ml <- csds.ml14

choiceshare <- as.data.frame(round(summary(csds.ml)$freq/sum(summary(csds.ml)$freq)*100,2))
colnames(choiceshare) <- c("Product","Share of Choice (%)")

shareofvolume <- aggregate(NETSPEND ~ product, FUN=sum, data=df_ind_summary)
shareofvolume$NETSPEND <- round(shareofvolume$NETSPEND/sum(shareofvolume$NETSPEND)*100,2)
colnames(shareofvolume) <- c("Product","Share of Revenue (%)")
shareofvolume$Product <- gsubfn(".",
                                    list(" " = "", "." = "", "(" = "", ")" = ""),
                                    as.character(shareofvolume$Product))

sharetable <- merge(choiceshare, shareofvolume) 
sharetablesorted <- sharetable[order(sharetable$'Share of Choice (%)', decreasing = TRUE),]
```

Panel scanner data allowed manufacturers and retailers to see not just brand share of sales volume or revenue, but also their share of choice (Kamakura & Russel 1989), the amount of times a consumer chooses to buy the brand over all others, regardless of the quantity that they buy. This is of high importance for manufacturers, who often want to drive revenue by increasing brand choice within the category, regardless of the size of the category. Shares of choice and volume of the 25 products can be seen in Appendix A, the largest product, Diet Coke, has a higher share of revenue (£) than of choice, implying that consumers have a high purchase quantity for this product.

The output of the full model results can be found in Appendix B coefficient on loyalty is positive, this aligns with the expectation that consumers are more likely to purchase a product that they previously showed loyalty to. This coefficient is important for manufacturers to understand about their category, if this coefficient is high, or is increasing over time, then this indicates that brand loyalty is particularly importance (or growing in importance), so more focus should be placed on improving brand image, or on engaging consumers early in their lifecycle, e.g. by targeting mothers or children. Although sugary drink manufacturers may need to be wary of this approach. If the coefficient is negative, or reducing, then this could indicate that consumers are exhibiting variety-seeking behaviour (Seetharaman & Chintagunta, 1998).

Brand share elasticity and cross elasticity can then be calculated from the price coefficient, by calculating the marginal effects and dividing by the percentage price change (Calculation details can be found in Appendix C). The consumer decision point that this is modeling is after the consumer has chosen what to buy (e.g. a canned drink), and how much to buy, which brand they then choose. Focussing on pepsi, we see that X has a high cross-price elasticity, implying that this is a strong competitor. This information is useful for pricing strategies, in particular the distinction between Every Day Low Prices (EDLP) strategies compared to promotional strategies (Shankar & Krishnamurthi, 1996). At a more operational level, price elasticity information is also useful for manufacturing company account managers and retailer buyers, who work together regularly to define promotional prices.

```{r elast}
load("csdsdata14.RData")

##Calculate Elasticity Matrix
elastdf <- setNames(data.frame(matrix(ncol = length(unique(csds.data$alt)), nrow = 0)), unique(csds.data$alt))
for (product1 in unique(csds.data$alt)){
  elast <- vector()
  for (product2 in unique(csds.data$alt)){
    #Calculate own share elasticity
    if (product1 == product2) {
      elast.temp <- mean(csds.ml$coefficients["price"]*csds.ml$probabilities[,product1]*(1-csds.ml$probabilities[,product1])) /
        mean(csds.ml$probabilities[,product1]) * mean(csds.data$price[csds.data$alt==product1]) } else {
    #Calculate cross share elasticity
      elast.temp <- -1*mean(csds.ml$coefficients["price"]*csds.ml$probabilities[,product1]*csds.ml$probabilities[,product2]) /
        mean(csds.ml$probabilities[,product1]) * mean(csds.data$price[csds.data$alt==product2]) }
    elast <- c(elast,round(elast.temp,4))}
  elastdf[product1,] <- elast}
```

The full set of elasticities and cross price elasticities are reported in Appendix D, importantly all cross price elasticities are positive, and own price elasticities are negative, indicating that when the price of a product goes up, consumers are less likely to buy that product, and more likely to buy other products, so the landscape of carbonated soft drinks is one made up of competitors. 

Once estimates of price elasticities and cross price elasticities have been derived, the competitive landscape can then be described using clout and vulnerability analysis, where clout is the sum of the outbound cross price elasticities, representing how much the brand’s price affects purchases of other brands, and vulnerability is the sum of the inbound cross price elasticities, representing how much the brand’s sales is dependent on other brands’ prices (Kamakura & Russel 1989). The clout and vulnerability for the top 10 brands in the CSD dataset is displayed below, where the size of the node represents the share of choice:

```{r fig.width=8}
elastdf_cv <- elastdf
elastdf_cv[row(elastdf_cv) == (col(elastdf_cv))] <- 0

clout <- as.data.frame(colMeans(elastdf_cv))
colnames(clout) <- "clout"
vuln <- as.data.frame(rowMeans(elastdf_cv))
colnames(vuln) <- "vulnerability"

cvdf <- cbind(clout,vuln, sharetable[,2])
colnames(cvdf)[3] <- "share"

cvdf$product<-rownames(cvdf)


ggplot(cvdf, aes(x=vulnerability, y=clout, size=share)) + 
  geom_point(color="#a6bddb") +
  geom_text(data=subset(cvdf, product %in% c("CocaColaRegular","Other","DietCokeDiet",
               "OwnBrandDiet","OwnBrandRegular","PepsiRegular", "MonsterRegular",
               "PepsiDiet","RedBullRegular","CocaColaZeroDiet")),
            aes(vulnerability,clout,label=product), size=3, col="#383838") + 
  theme_bw() + theme(legend.position = "none")
```

Unlabeled: 7UpDiet, 7UpRegular , CocaColaLifeRegular , DrPepperRegular, FantaRegular, OldJamaicaRegular , RelentlessRegular, RubiconRegular, TangoRegular, FantaDiet.

The strong brands such as Diet Coke and Pepsi have relatively high clout and lower vulnerability, whereas the more niche brands are clustered together with higher vulnerability and low clout. This is to be expected as consumers are less likely to switch from strong brands to niche brands as a result of a price change from the niche brand, but they are likely to change their choice due to price changes from a strong brand. It is interesting that in this datset Regular Pepsi has low clout and high vulnerability even though it has a high share of choice. This may mean that it is a common "second choice alternative" to the other strong brands when they have a higher price. 

This market structure analysis can be useful for brands to understand where they stand in the competitive landscape.  As this market structure is likely to change over time e.g. when new products enter the market (Van Heerde, Mela & Manchanda, 2004). It is also important for an analyst to regularly repeat this analysis, and show the changes over time. This analysis can show which brands are starting to compete more with each other, for example that SUVs used to compete more strongly with vans, then grew to compete more competitively with cars (Luan, Sudhir & Norris 2007).   

Panel scanner data also allowed businesses to understand how promotional activity affected consumers at an individual level. Clout and vulnerability analysis can also be done on a promotional / advertising basis, to understand how much the sales of brands are impacted by the promotions of other brands, and there can be a more detailed analysis of the points at which consumers switch between brands, or out of the category.

It is possible to  build a predictive choice model with a multinomial choice neutral network (Ripley & Venables, 2016), however these lack interpretability in terms of which factors are contributing to choice, which are really the key insights for business practicitioners. It is not much use to be able to predict an individual's choice, but rather it is beneficial to understand the mechanisms behind that choice. The neural network approach may be beneficial, however, in simulations of consumer choice given a different competitive price structure, e.g. to see what the expected aggregate response would be given a change in price of one of the products.

##Extension to full choice model

![Brand Choice Decision Tree, as per structure of Sismiero (2017).](mldt.png)

The multinomial logit model of brand choice (as per Figure 1) assumes that the consumer is making a purchase within the category. It focuses on brand choice, and ignores other key business questions such as: what are the drivers for how often consumers come to the shop, and for how much they buy when they are there. As mentioned in Guadagni & Little (1983), this has little value to the retailer, who is interested in total spend at their store, and also has limitations for the manufacturers who are interested not only in brand share but in purchase incidence and quantity in the category.

![Branch Choice and Purchase Incidence Decision Tree, as per structure of Sismiero (2017).](mldt_pi.png)

One of the commonly used modelling techniques to cater for purchase incidence is the nested logit model (Guadagni & Little, 1998). This makes a broader assumption that the consumer is making a shopping trip, and then models whether the consumer will make a purchase within the category, and subsequently what their brand choice would be. The nested approach first estimates the traditional multinomial logit, and then uses the concept of "category attractiveness", to add the additional layer of product category choice on top of this. This handles the case where multiple products are purchased in one shopping trip, as it caters for multiple purchase opportunities within one shopping trip, in which the consumer may or may not purchase the same item. 

![Brand Choice, Purchase Incidence and Purchase Quantity Tree, as per structure of Sismiero (2017).](mldt_pipq.png)


This can then further be extended to purchase quantity, as has been done by (Gupta, 1998; Chiang 1991; Chintagunta 1993; Bucklin, Gupta & Siddarth 1998). For this, a zero-truncated Poisson model is often used (e.g. in Bucklin, Gupta & Siddarth 1998), to model count data where it is known that the count is greater than 0, which is the case in this situation as this model occurs after we know the consumer has made a purchase of the brand. The quantity elasticity that is produced by this model is total purchase elasticity, and this can be added to the brand choice elasticity from the multinomial logit model to get the overall elasticity.

The interaction between purchase quantity promotion elasticity and brand switching promotion elasticity are important for the discussion between retailers and manufacturers. Manufacturers care about increasing the overall sales volume of their brand, so purchase quantity and brand switching elasticities are important to them, however the retailer doesn’t benefit from consumers’ brand switching, as they lose the revenue brands consumers are switching from (Srinivasan et al 2004). It is important for both parties to have good estimates of both the elasticities in order to make their decisions properly, but the corresponding actions are likely to differ. 

![Brand Choice, Purchase Incidence, Purchase Quantity and Retailer Choice Tree, as per structure of Sismiero (2017).](mldt_pipqrc.png)

An additional layer could also be added to model the choice of retailer e.g. by Bucklin & Lattin (1992) as per Figure 5. 

#Modelling considerations

Much research has been done using UPC scanner data to produce models for consumer purchasing decisions, and many additional subtleties and complexities that can be encorporated into the models have been identified. The models can be extended in a variety of ways to cater to more nuanced consumer behaviour. For example, there is evidence that consumers do not always respond directly to price, but compare prices to a “reference price”, how much they think the item should cost (Winer 1986). There are of course difficulties with modelling this internal psychological price, but proxies for it can be made by using average price for comparable products on that day, the price last paid for the product by that consumer, or the average price for the product. There may also be an additional mechanism where consumers may have different responses to a price above the reference point than to a price below (Krishnamurthi, Mazumdar & Raj 1992), following the “loss aversion” research of Kahneman and Tversky (1991).

Consumers may also have internal price “thresholds” and change their choice only if a competitor brand is below a threshold, or their usual brand is above a threshold. These thresholds could also be relative to a dynamic reference price. Reference thresholds could be estimated for consumers or consumer segments, and included in the model (Han, Gupta & Lehmann 2001).

There is evidence that suggests that the price elasticity may also change across the life-cycle of the product (Simon 1979, Parker 1992), Bijmolt, Heerde and Pieters (2005) found that price elasticities in general have been increasing over time, whereas share elasticities have remained quite constant. Elasticities may also be store dependent (Hoch et al 1995). How these mechanisms relate have key business implications, such as how to structure a pricing strategy over a product lifecycle (Bijmolt, Heerde and Pieters, 2005), and how to manage promotional pricing across retailers.

Additional loyalty variables could also be calculated in addition to the product-loyalty calculated above, including higher level brand loyalty (e.g Pepsi / Coca Cola), package-size loyalty (Guadagni & Little 1983) and flavour loyalty, to split out the specific consumer reactions to product attributes.

Some approaches also include an inventory variable (e.g. Chintagunta 1993) by estimating a consumer’s consumption rate during the initialisation period, then estimating their “inventory” of the product at the time they shop, by adding to the inventory variable every time they make a purchase, and making reductions from it at the calculated rate of consumption.

Choice models can be extended to include multiple "states" of consumer behaviour, e.g. planned purchases and spontaneous purchases. (Bucklin and Little, 1991). Walsh (1995) suggests an alternative model for cases in which there are often multiple different products purchased on each shopping occasion, which can be the case for carbonated soft drinks. This alternative model focusses on the "assortment" of goods that a consumer has in their inventory, and takes into account that the consumer purchase goods for unknown future occasions and may therefore value variety. Dubé (2004) offers another model to handle this case.

Bucklin & Gupta (1992) added another refinement to the model by including household response segements, grouping households by how they react to price and promotion variables, and then estimating their responses as a group. This caters for some of the heterogeneity amongst consumers, and by maintaining groups instead of going to the individual level, the reported segment variables are "managerially interpretable" Guadagni & Little (1998). Bucklin, Gupta & Siddarth (1998) continue this segmentation approach across the three tiers of purchase incidence, brand choice, and purchase quantity.

The model could be further extended by splitting the base price and the promotional price, in this case that would require using a categorisation of promotion descriptions either with a look-up table, or using NLP techniques, or by comparing average non-promotional prices to promotional prices.

Consumer segments can also be created based on choice behaviour (REFERENCE) , often in the literature consumers are split up into “loyal” and “switching” consumers (Kamakura & Russel 1989). Clout and vulnerability analysis can also be repeated on consumer segments, to understand how the competitive structure differs across these, which can be useful for developing segment-targeted marketing and product strategies.

Each of these additional elements lead to a more refined model, catering for additional consumer considerations and behaviours, unfortunately in most cases they also lead to additional computational complexity, and if care is not taken, to results that are less easy to interpret by a retail professional. 

If one of the purposes of the analysis is to understand pricing strategies then the inclusion of the more nuanced consumer price response behaviours would provide a much more useful model than the price elasticity of the “basic” model. However, if the purpose is to undercover product attribute importance or promotional effects, then it may not be worth the additional modelling effort to establish the reference and threshold points, simply to reduce the bias of the model.

##Limitations

Evidence has shown that marketing executives often make price promotion decisions intuitively rather than relying on the outputs of the empirical methods discussed above (Bogomolova, Szabo & Kennedy, 2017). Many of the theoretical and academic approaches are highly complex, have complex outcomes, and can use esoteric language. These two facts are very likely linked. The outcomes of retail modelling approaches must be clear and actionable, and ideally the mechanisms to achieve those outcomes must be understandable (Neslin et al., 1994).

However, there is empirical evidence that analysing consumer data, including panel data, has a positive impact on company financial performance (Germann et al., 2014). So it is the job of the analyst to ensure that the outputs are meaningful, using the clout and visualisation framework may help here, or displaying visual simulations of changes to the marketing mix.

##Choice Model Applications

Choice models can also be used outside of the retail space, for example to model how people choose: a profession (Boskin, 1974), a house and mode of commute (Pinjari et al, 2011), where to attend college (Long, 2004), choice of vehicle (Berkovec 1985). The important considerations to take when deciding whether to use a choice model include:

* Whether the analyst has access to the information of available alternatives (e.g. what other cars are on the market)
*	Whether a high percentage of the variables are available on which the individuals are expected to make their decisions (e.g. the price, number of doors)
* Whether the relevant decision making behaviours can be modelled or proxied sufficiently (e.g. whether there is information on the existence of, or values for reference prices and thresholds in the situation)
* Whether there are enough decisions to make the analysis statistically significant

##Additional Data Sources

The agencies that produce these datasets now also run econometric models and provide reports, analysis and consultancy to businesses (Neilsen, 2017). Therefore, for a data scientist beginning to explore this data for a business, it is worth first understanding what types of reporting and analysis that business is already receiving from the data provider. If a data scientist is charged with getting insights from this data it may be because the business:

* Is not willing to pay for the pre-packaged results from the data provider, in which case the above techniques apply.
* Wants a custom model including variables or behaviours that are specific to their industry, in which case the above techniques and the model extension discussion applies, and there may well be additional modelling steps.
* Wants to merge the data with another dataset, to get additional insights.

This section focusses on the last reason, in particular the new datasets that are available for business to access, and how they link to customer choice data.

Consumer choice models have previously been extended to include economic conditions (reference), which may impact a consumer’s price elasticity, or choice behaviour. For the purchase quantity model it may also be useful to include weather data, but this is less likely to be useful for the brand choice model, as the weather isn’t clearly linked to consumers’ price or promotion elasticity, so inclusion may improve the prediction rate, but omission is unlikely to cause bias. 

In more recent years in-store panel data has been linked to online sales data, to compare consumer behaviour as a whole, or analyse how it differs across those two channels. There are many elements that may differ including price elasticity (Degeratu, Rangaswamy and Wu, 2000) and brand loyalty (Danaher, Wilson and Davis 2003).

There has been an explosion over the last decade in data that consumers provide freely relating to their shopping habits, their product preferences, and their decision making behaviour. A major force driving this is the increase in usage of social media sites such as twitter where consumers post publically about their daily experiences.

Social media “exposure”, as a form of advertising that could also include organic conversation about the brand, could be measured and included into the choice model as a product specific attribute that changes over time (Liu & Lopez 2016). This could also be further broken down into positive or negative exposure based on sentiment analysis of the social media content. This could further be extended to exposure to nutritional social media discussions such as sugar and caffeine (as in Liu & Lopez 2016), or to ingredients, flavours or other product attributes. 

Social media data could also be used to complement the outcomes of the statistical analysis. If the model shows high absolute brand choice price elasticity to a competitor brand, then qualitative analysis of social media data, the conversations that consumers are having when the mention the two brands, could identify what features consumers see as important. Data science techniques such as word embedding (Golberg & Levy 2014) could be used here to identify language that corresponds to brand-switching, to pick out relevant blogs or tweets to analyse.

There are clearly some limitations of using social media in this analysis, and monitoring sentiment on social media does not always lead to robust predictions. Consumers that regularly access social media sites are a growing proportion across age groups, but social media exposure is likely to be more impactful for specific age groups (Correa, Hinsley and De Zuniga 2010). 

##Conclusion

Before the introduction of panel scanner data, the modelling of consumer choice had been largely dominated by psychological and sociological theory. The future of consumer choice research should be data-driven, rooted in the known principles of psychology, but also coherent to business practitioners. The academic fields are already starting to form a symbiotic relationship where each informs the other to build strong and predictive models of consumer choice, and professional agencies are working on bringing those insights to business practitioners. As the field progresses, these links will likely tighten, and additional data sources will be added more and more from social media and other modern platforms.

Consumer choice models are powerful tools, and can be beneficial to both retailers and manufacturers while deciding on the elements of the marketing mix, but care must be taken that the models are constructed meaningfully, and explained correctly and intuitively to business practitioners. As in all statistical enterprises, the quality of the model is limited by the quality and quantity of the input data. The analyst should strive as much as possible to have a full list of variables as discussed. There are many decisions that should be taken when producing a model of consumer choice, and close attention should be paid to the impact of those decisions, from data preprocessing, model specification, and visualisation of results.

##References

Andrews, R.L. and Currim, I.S., (2005) An experimental investigation of scanner data preparation strategies for consumer choice models. *International Journal of Research in Marketing*. 22(3), 319-331.

Bijmolt, T.H., Heerde, H.J.V. and Pieters, R.G. (2005) New empirical generalizations on the determinants of price elasticity. *Journal of Marketing Research*. 42(2), 141-156.

Bogomolova, S., Szabo, M. and Kennedy, R., (2017) Retailers' and manufacturers' price-promotion decisions: Intuitive or evidence-based?. *Journal of Business Research*. 76, 189-200.

Berkovec, J. and Rust, J. (1985) A nested logit model of automobile holdings for one vehicle households. *Transportation Research Part B: Methodological*. 19(4), 275-285.

Boskin, M.J. (1974) A Conditional Logit Model of Occupational Choice. *Journal of Political Economy*. 82(2, Part 1), 389–398.

Bucklin, R.E. and Gupta, S. (1999) Commercial Use of UPC Scanner Data: Industry and Academic Perspectives. *Marketing Science*. 18(3), 247–273.

Bucklin, R.E., Gupta, S. and Siddarth, S. (1998) Determining segmentation in sales response across consumer purchase behaviors. *Journal of Marketing Research*. 189-197.

Bucklin, R.E. and Lattin, J.M.(1991) A two-state model of purchase incidence and brand choice. *Marketing Science*. 10(1), 24-39.

Bucklin, R.E. and Lattin, J.M., (1992) A model of product category competition among grocery retailers. *Journal of Retailing*. 68(3), 271.

Chintagunta, P.K., (1993) Investigating Purchase Incidence, Brand Choice and Purchase Quantity Decisions of Households. *Marketing Science*. 12(2), 184–208.

Correa, T., Hinsley, A.W. and De Zuniga, H.G. (2010) Who interacts on the Web?: The intersection of users’ personality and social media use. *Computers in Human Behavior*. 26(2), 247-253.

Croissant, Y. (2012) *Estimation of multinomial logit models in R: The mlogit Packages. R package version 0.2-2*. Available from: http://cran.r-project.org/web/packages/mlogit/vignettes/mlogit.pdf [Accessed August 24th 2017]

Ripley, B., Venables, W. (2016) *Package ‘nnet’. R package version*. Available from: https://cran.r-project.org/web/packages/nnet/nnet.pdf [Accessed August 24th 2017]

Danaher, P.J., Wilson, I.W. and Davis, R.A. (2003) A comparison of online and offline consumer brand loyalty. *Marketing Science*. 22(4), 461-476.

Degeratu, A.M., Rangaswamy, A. and Wu, J. (2000) Consumer choice behavior in online and traditional supermarkets: The effects of brand name, price, and other search attributes. *International Journal of research in Marketing*. 17(1), 55-78.

Dubé, J.P., (2004) Multiple discreteness and product differentiation: Demand for carbonated soft drinks. *Marketing Science*. 23(1), 66-81.

Fader, P.S. and Hardie, B.G. (1996) Modeling consumer choice among SKUs. *Journal of marketing Research*. 442-452.

Germann et al. (2014) Do Retailers Benefit from Deploying Customer Analytics? *Journal of Retailing*. 90(4), 587–593.

Google Ngrams, (2008) *Representation of frequency of the terms "marketing science" and "UPC Scanner" in the Google ngram corpus from 1970 to 2008, digital image of data, Google Ngrams* Available from: https://books.google.com/ngrams/graph?content=UPC+scanner%2Cmarketing+science&year_start=1970&year_end=2008&corpus=15&smoothing=2&share=&direct_url=t1%3B%2CUPC%20scanner%3B%2Cc0%3B.t1%3B%2Cmarketing%20science%3B%2Cc0 [Accessed 10th August 2017]

Guadagni, P.M. and Little, J.D. (1983) A Logit Model of Brand Choice Calibrated on Scanner Data. *Marketing Science*, 2(3). 203–238.

Guadagni, P.M. and Little, J.D. (1998) When and what to buy: a nested logit model of coffee purchase. *Journal of Forecasting*. 17(3‐4), 303–326.

Guadagni, P.M. and Little, J.D. (2008) A Logit Model of Brand Choice Calibrated on Scanner Data: A 25th Anniversary Perspective. *Marketing Science*. 27(1), 26–28.

Gupta, S. (1988) Impact of Sales Promotions on When, What, and How Much to Buy. *Journal of Marketing Research*. 25(4), 342–355.

Goldberg, Y. and Levy, O. (2014) *word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method*. Available from: https://arxiv.org/abs/1402.3722 [Accessed 24th August 2017]

Han, S., Gupta, S. and Lehmann, D.R. (2001) Consumer price sensitivity and price thresholds. *Journal of retailing*. 77(4), 435-456.

Hoch, S. et al. (1995) Determinants of Store-Level Price Elasticity. *Journal of Marketing Research* 32(1), 17.

Tversky, A. and Kahneman, D. (1991) Loss aversion in riskless choice: A reference-dependent model. *The Quarterly Journal of Economics*. 106(4), 1039-1061.

Kamakura, W.A. and Russell, G. (1989) A probabilistic choice model for market segmentation and elasticity structure. *Journal of Marketing Research*. 24, 379-390.

Krishnamurthi, L., Mazumdar, T. & Raj, S.P. (1992) Asymmetric Response to Price in Consumer Brand Choice and Purchase Quantity Decisions. *Journal of Consumer Research*. 19(3), 387–400.

Liu, Y. and Lopez, R.A. (2016) The impact of social media conversations on consumer brand choices. *Marketing Letters,* 27(1), 1-13.

Long, B.T. (2004) How have college decisions changed over time? An application of the conditional logistic choice model. *Journal of Econometrics*. 121(1), 271-296.

Luan, J.Y., Sudhir, K. and Norris, B. (2007) *Dynamic market structure in a durable goods market: The effect of a new product form*. Yale School of Management. Available from: http://faculty.som.yale.edu/ksudhir/workingpapers/MktStr-JMR.pdf [Accessed  21st August 2017]

Malik, S.A. (2015) *Optimising supermarket promotions of fast moving consumer goods using disaggregated sales data: A case study of Tesco and their small and medium sized suppliers*. Doctoral dissertation, University of Kent.

Neslin et al. (1994) A research agenda for making scanner data more useful to managers. *Marketing Letters* 5(4), 395–411

Neilsen (2017) *Consumer Insight Solutions* Available from: http://www.nielsen.com/uk/en/solutions/consumer-insights.html [Accessed 24th August 2017]

Parker, P. (1992) Price Elasticity Dynamics Over the Adoption Life Cycle. *Journal of Marketing Research*. 29(3), 358–367.

Pinjari, A. et al. (2011) Modeling the choice continuum: an integrated model of residential location, auto ownership, bicycle ownership, and commute tour mode choice decisions. *Transportation*. 38(6), 933–958.

Seetharaman, P.B. and Chintagunta, P. (1998) A model of inertia and variety-seeking with marketing variables. *International Journal of Research in Marketing* 15(1), 1-17.

Simon, H. (1979) Dynamics of Price Elasticity and Brand Life Cycles: An Empirical Study. *Journal of Marketing Research*. 16(4), p.439.

Sismeiro, C., (2017). *Retail Analytics* [Lecture] Msc Business Analytics, Imperial College London.

Shankar V. & Krishnamurthi, L. (1996) Relating price sensitivity to retailer promotional variables and pricing policy: an empirical analysis. *Journal of Retailing*. 72(3), 249–272.

Srinivasan, S., Pauwels, K., Hanssens, D.M. and Dekimpe, M.G. (2004) Do promotions benefit manufacturers, retailers, or both? *Management Science*. 50(5), 617-629.

Van Heerde, H.J., Mela, C.F. and Manchanda, P., (2004) The dynamic effect of innovation on market structure. *Journal of Marketing Research*. 41(2), 166-183.

Walsh, J.W., (1995) Flexibility in consumer purchasing for uncertain future tastes. *Marketing Science*. 14(2), 148-165.

Winer, R.S. (1986) A reference price model of brand choice for frequently purchased products. *Journal of Consumer Research* 13(2), 250-256.

Zhang, J. (2006) An Integrated Choice Model Incorporating Alternative Mechanisms for Consumers; Reactions to In-Store Display and Feature Advertising. *Marketing Science*. 25(3), 278–290.

\newpage

##Appendix A

```{r appA}
kable(sharetablesorted, row.names = FALSE)
```

\newpage

##Appendix B

```{r appB, cache=FALSE}
tabletoshow <- mlogittotable(csds.ml)
tabletoshow$variables <- as.character(tabletoshow$variables)
tabletoshow$variables <- gsubfn(".", list(":" = " - "), tabletoshow$variables)
kable(tabletoshow)
```

\newpage

##Appendix C - Elasticity Calculation Method

Elaticities are calculated using the formulas below:

Own Price Elasticity of product i = 
$$\frac{\beta_{price} 1/n\sum{P_{i,h,t}(1-P_{i,h,t}}) \overline{price_{i}}}{1/n\sum{P_{i,h,t}}}$$

Cross Price Elasticity of product i to price j = 

$$-1 * \frac{\beta_{price} 1/n\sum{P_{i,h,t}P_{j,h,t}} \overline{price_{j}}}{1/n\sum{P_{i,h,t}}}$$

Where $P_{i}$ is the vector of probabilities that each household h chose product i at the training shopping trip t, which is estimated as part of the multinomial logit model, $\overline{price_i}$ is the average price of product i. These elasticites are calculated at the average price, as opposed to calculating all the individual elasticities and averaging them.

\newpage

##Appendix D - Calculated Elasticities

```{r cache=FALSE}
names(elastdf) <- paste("p",1:20)
kable(elastdf[,1:10])
```

```{r cache=FALSE}
kable(elastdf[,11:20])
```

Where "p i" refers to the ith product in the below table, ordered by share of choice:

```{r}
kable(data.frame(number= paste("p",1:20), product = rownames(elastdf)))
```